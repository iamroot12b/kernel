/*
 *  arch/arm/include/asm/assembler.h
 *
 *  Copyright (C) 1996-2000 Russell King
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2 as
 * published by the Free Software Foundation.
 *
 *  This file contains arm architecture specific defines
 *  for the different processors.
 *
 *  Do not include any C declarations in this file - it is included by
 *  assembler source.
 */
#ifndef __ASM_ASSEMBLER_H__
#define __ASM_ASSEMBLER_H__

#ifndef __ASSEMBLY__
#error "Only include this from assembly code"
#endif

#include <asm/ptrace.h>
#include <asm/domain.h>
#include <asm/opcodes-virt.h>
#include <asm/asm-offsets.h>
#include <asm/page.h>
#include <asm/thread_info.h>

#define IOMEM(x)	(x)

/*
 * Endian independent macros for shifting bytes within registers.
 */
#ifndef __ARMEB__
#define lspull          lsr
#define lspush          lsl
#define get_byte_0      lsl #0
#define get_byte_1	lsr #8
#define get_byte_2	lsr #16
#define get_byte_3	lsr #24
#define put_byte_0      lsl #0
#define put_byte_1	lsl #8
#define put_byte_2	lsl #16
#define put_byte_3	lsl #24
#else
#define lspull          lsl
#define lspush          lsr
#define get_byte_0	lsr #24
#define get_byte_1	lsr #16
#define get_byte_2	lsr #8
#define get_byte_3      lsl #0
#define put_byte_0	lsl #24
#define put_byte_1	lsl #16
#define put_byte_2	lsl #8
#define put_byte_3      lsl #0
#endif

/* Select code for any configuration running in BE8 mode */
#ifdef CONFIG_CPU_ENDIAN_BE8
#define ARM_BE8(code...) code
#else
#define ARM_BE8(code...)
#endif

/*
 * Data preload for architectures that support it
 */
#if __LINUX_ARM_ARCH__ >= 5
#define PLD(code...)	code
#else
#define PLD(code...)
#endif

/*
 * This can be used to enable code to cacheline align the destination
 * pointer when bulk writing to memory.  Experiments on StrongARM and
 * XScale didn't show this a worthwhile thing to do when the cache is not
 * set to write-allocate (this would need further testing on XScale when WA
 * is used).
 *
 * On Feroceon there is much to gain however, regardless of cache mode.
 */
#ifdef CONFIG_CPU_FEROCEON
#define CALGN(code...) code
#else
#define CALGN(code...)
#endif

/*
 * Enable and disable interrupts
 */
#if __LINUX_ARM_ARCH__ >= 6
	.macro	disable_irq_notrace
	cpsid	i
	.endm

	.macro	enable_irq_notrace
	cpsie	i
	.endm
#else
	.macro	disable_irq_notrace
	msr	cpsr_c, #PSR_I_BIT | SVC_MODE
	.endm

	.macro	enable_irq_notrace
	msr	cpsr_c, #SVC_MODE
	.endm
#endif

	.macro asm_trace_hardirqs_off
#if defined(CONFIG_TRACE_IRQFLAGS)
	stmdb   sp!, {r0-r3, ip, lr}
	bl	trace_hardirqs_off
	ldmia	sp!, {r0-r3, ip, lr}
#endif
	.endm

	.macro asm_trace_hardirqs_on_cond, cond
#if defined(CONFIG_TRACE_IRQFLAGS)
	/*
	 * actually the registers should be pushed and pop'd conditionally, but
	 * after bl the flags are certainly clobbered
	 */
	stmdb   sp!, {r0-r3, ip, lr}
	bl\cond	trace_hardirqs_on
	ldmia	sp!, {r0-r3, ip, lr}
#endif
	.endm

	.macro asm_trace_hardirqs_on
	asm_trace_hardirqs_on_cond al
	.endm

	.macro disable_irq
	disable_irq_notrace
	asm_trace_hardirqs_off
	.endm

	.macro enable_irq
	asm_trace_hardirqs_on
	enable_irq_notrace
	.endm
/*
 * Save the current IRQ state and disable IRQs.  Note that this macro
 * assumes FIQs are enabled, and that the processor is in SVC mode.
 */
	.macro	save_and_disable_irqs, oldcpsr
#ifdef CONFIG_CPU_V7M
	mrs	\oldcpsr, primask
#else
	mrs	\oldcpsr, cpsr
#endif
	disable_irq
	.endm

	.macro	save_and_disable_irqs_notrace, oldcpsr
	mrs	\oldcpsr, cpsr
	disable_irq_notrace
	.endm

/*
 * Restore interrupt state previously stored in a register.  We don't
 * guarantee that this will preserve the flags.
 */
	.macro	restore_irqs_notrace, oldcpsr
#ifdef CONFIG_CPU_V7M
	msr	primask, \oldcpsr
#else
	msr	cpsr_c, \oldcpsr
#endif
	.endm

	.macro restore_irqs, oldcpsr
	tst	\oldcpsr, #PSR_I_BIT
	asm_trace_hardirqs_on_cond eq
	restore_irqs_notrace \oldcpsr
	.endm

/*
 * Get current thread_info.
 */
	.macro	get_thread_info, rd
 ARM(	mov	\rd, sp, lsr #THREAD_SIZE_ORDER + PAGE_SHIFT	)
 THUMB(	mov	\rd, sp			)
 THUMB(	lsr	\rd, \rd, #THREAD_SIZE_ORDER + PAGE_SHIFT	)
	mov	\rd, \rd, lsl #THREAD_SIZE_ORDER + PAGE_SHIFT
	.endm

/*
 * Increment/decrement the preempt count.
 */
#ifdef CONFIG_PREEMPT_COUNT
	.macro	inc_preempt_count, ti, tmp
	ldr	\tmp, [\ti, #TI_PREEMPT]	@ get preempt count
	add	\tmp, \tmp, #1			@ increment it
	str	\tmp, [\ti, #TI_PREEMPT]
	.endm

	.macro	dec_preempt_count, ti, tmp
	ldr	\tmp, [\ti, #TI_PREEMPT]	@ get preempt count
	sub	\tmp, \tmp, #1			@ decrement it
	str	\tmp, [\ti, #TI_PREEMPT]
	.endm

	.macro	dec_preempt_count_ti, ti, tmp
	get_thread_info \ti
	dec_preempt_count \ti, \tmp
	.endm
#else
	.macro	inc_preempt_count, ti, tmp
	.endm

	.macro	dec_preempt_count, ti, tmp
	.endm

	.macro	dec_preempt_count_ti, ti, tmp
	.endm
#endif

#define USER(x...)				\
9999:	x;					\
	.pushsection __ex_table,"a";		\
	.align	3;				\
	.long	9999b,9001f;			\
	.popsection

#ifdef CONFIG_SMP
#define ALT_SMP(instr...)					\
9998:	instr
/*
 * Note: if you get assembler errors from ALT_UP() when building with
 * CONFIG_THUMB2_KERNEL, you almost certainly need to use
 * ALT_SMP( W(instr) ... )
 */
#define ALT_UP(instr...)					\
	.pushsection ".alt.smp.init", "a"			;\
	.long	9998b						;\
9997:	instr							;\
	.if . - 9997b != 4					;\
		.error "ALT_UP() content must assemble to exactly 4 bytes";\
	.endif							;\
	.popsection
#define ALT_UP_B(label)					\
	.equ	up_b_offset, label - 9998b			;\
	.pushsection ".alt.smp.init", "a"			;\
	.long	9998b						;\
	W(b)	. + up_b_offset					;\
	.popsection
#else
#define ALT_SMP(instr...)
#define ALT_UP(instr...) instr
#define ALT_UP_B(label) b label
#endif

/*
 * Instruction barrier
 */
	.macro	instr_sync
#if __LINUX_ARM_ARCH__ >= 7
	isb
#elif __LINUX_ARM_ARCH__ == 6
	mcr	p15, 0, r0, c7, c5, 4
#endif
	.endm

/*
 * SMP data memory barrier
 */
	.macro	smp_dmb mode
#ifdef CONFIG_SMP
#if __LINUX_ARM_ARCH__ >= 7
	.ifeqs "\mode","arm"
	ALT_SMP(dmb	ish)
	.else
	ALT_SMP(W(dmb)	ish)
	.endif
#elif __LINUX_ARM_ARCH__ == 6
	ALT_SMP(mcr	p15, 0, r0, c7, c10, 5)	@ dmb
#else
#error Incompatible SMP platform
#endif
	.ifeqs "\mode","arm"
	ALT_UP(nop)
	.else
	ALT_UP(W(nop))
	.endif
#endif
	.endm

#if defined(CONFIG_CPU_V7M)
	/*
	 * setmode is used to assert to be in svc mode during boot. For v7-M
	 * this is done in __v7m_setup, so setmode can be empty here.
	 */
	.macro	setmode, mode, reg
	.endm
#elif defined(CONFIG_THUMB2_KERNEL)
	.macro	setmode, mode, reg
	mov	\reg, #\mode
	msr	cpsr_c, \reg
	.endm
#else
	.macro	setmode, mode, reg
	msr	cpsr_c, #\mode
	.endm
#endif

/*
 * Helper macro to enter SVC mode cleanly and mask interrupts. reg is
 * a scratch register for the macro to overwrite.
 *
 * This macro is intended for forcing the CPU into SVC mode at boot time.
 * you cannot return to the original mode.
 */
<<<<<<< HEAD
 /**
  * @[charles.hyunchul-JO]:2015.07.06
  check define value as below -> root/arch/arm/include/asm/ptrace.h
	#define PSR_F_BIT	0x00000040
	#define PSR_I_BIT	0x00000080
	#define PSR_A_BIT	0x00000100 //V6 arch?Ì»? ????, ??????À¸?? V7/M ??????, Abot bit??.
	#define PSR_E_BIT	0x00000200
	#define PSR_J_BIT	0x01000000
	#define PSR_Q_BIT	0x08000000
	#define PSR_V_BIT	0x10000000
	#define PSR_C_BIT	0x20000000
	#define PSR_Z_BIT	0x40000000
	#define PSR_N_BIT	0x80000000
=======
/*
 * ê³µí†µ : 7ì›”4ì¼ ë¯¸ì™„ë£Œ ì°¨ì£¼ ìë£Œ ì¶”ê°€í•´ì„œ ë…¼ì˜
>>>>>>> 4de9132293dfebfbf6fb663600918a3c8632e15b
 */
.macro safe_svcmode_maskall reg:req
    /*
     * raspberry pi 2ëŠ” LINUX_ARM_ARCH 7ì´ê³  CONFIG_CPU_V7ì´ë¯€ë¡œ
     * ì•„ë˜ì˜ #if directiveëŠ” true
     */
#if __LINUX_ARM_ARCH__ >= 6 && !defined(CONFIG_CPU_V7M)
    /*
     * instruction descriptions
     *
     * xor : XOR ë…¼ë¦¬ ì—°ì‚°ì„ ì´ìš©í•œ ë¹„êµ ëª…ë ¹ì–´
     * tst : AND ë…¼ë¦¬ ì—°ì‚°ì„ ì´ìš©í•œ ë¹„êµ ëª…ë ¹ì–´
     * bic : íŠ¹ì • ë¹„íŠ¸ê°’ì„ 0ìœ¼ë¡œ í´ë¦¬ì–´
     * orr : 32bit or ë…¼ë¦¬ ì—°ì‚°
     * adr : ì£¼ì†Œê°’ì„ ë ˆì§€ìŠ¤í„°ì— ì €ì¥í•˜ëŠ” ì˜ì‚¬ ëª…ë ¹ì–´
     *       pc ìƒëŒ€ ë§ì…ˆ ëº„ì…ˆì„ ì´ìš©í•˜ì—¬ ì£¼ì–´ì§„ labelì˜ ì£¼ì†Œë¥¼ ë ˆì§€ìŠ¤í„°ì— ì €ì¥
     * msr : psr ë ˆì§€ìŠ¤í„° ì „ìš© mov ëª…ë ¹ì–´(ì“°ê¸°)
     * bne : branch instruction B with the condition mnemonic NE (not equal)
     *       if the previous compare instruction sets the condition flags
     *       to not equal, the branch instruction is executed.
     */
/*
 * ê³µí†µ : HYP_MODE => cprs ì—ì„œ ì„¤ì •ëœ ëª¨ë“œ, ì±…ì— ë‚˜ì˜¤ì§€ ì•Šì€ ì‹ ê·œ ëª¨ë“œ ...
 * SVC ëª¨ë“œ ë³´ë‹¤ ë†’ì€ ëª¨ë“œ í™•ì¸ í•„ìš” ~!!!!!
 * ê°€ìƒí™”ê´€ë ¨ 
 */

    /*
     * cpsrì„ ì½ì–´ í˜„ì¬ modeê°€ HYP_MODEì¸ì§€ ê²€ì‚¬
     * eorë¡œ í˜„ì¬ HYP_MODEì¸ ê²½ìš°ì—ë§Œ MODE_MASKì— í•´ë‹¹í•˜ëŠ” bitsê°€ ëª¨ë‘ 0ì´ ë¨
     * tstë¡œ HYP_MODEì¸ ê²½ìš°ì—ë§Œ Zero flagê°€ 1ë¡œ ì„¤ì • ë¨(Z)
     */
	mrs	\reg , cpsr
	eor	\reg, \reg, #HYP_MODE
	tst	\reg, #MODE_MASK

    /*
     * MODE_MASK(0x0000001F)ì— í•´ë‹¹ í•˜ëŠ” bitë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”
     * SVC_MODEë¥¼ ë§Œë“¤ê¸° ìœ„í•œ ì„ í–‰ ì‘ì—…
     * IRQ, FIQë¥¼ ë§‰ê³ , SVC_MODEë¥¼ ì„¤ì •
     * THUMBì¼ë•ŒëŠ” Thumb ë¹„íŠ¸ë¥¼ turn on
     */
	bic	\reg , \reg , #MODE_MASK
	orr	\reg , \reg , #PSR_I_BIT | PSR_F_BIT | SVC_MODE
THUMB(	orr	\reg , \reg , #PSR_T_BIT	)

    /*
     * ì´ì „ì˜ tst ë¹„êµì—°ì‚°ì—ì„œ HYP_MODEì—ì„œë§Œ Zero flagê°€ 1ë¡œ ì„¤ì •(Z) ë˜ì—ˆê¸° ë•Œë¬¸ì—
     * Zero flagê°€ 0ì¼ë•Œ(z)ë§Œ jumpí•˜ëŠ” bneëŠ” HYP_MODEì—ì„œëŠ” falseê°€ ë˜ì–´ ì‹¤í–‰í•˜ì§€ ì•ŠëŠ”ë‹¤.
     * ì¦‰, HYP_MODEê°€ ì•„ë‹Œê²½ìš°ì— 1fë¡œ jump
     */
	bne	1f

    /*
     * arch/arm/include/asm/unidifed.h
     * #idfed CONFIG_THUMB2_KERNEL
     * #define BSYM(sym)    sym + 1
     * #else
     * #define BSYM(sym)    sym ()
     * #endif
     *
     * adr  lr, 2f + 1
     * lr = pc relative 2f + 1
     * lr = 2f address + 1
     *
     * kernel disassemble ê²°ê³¼
     * 6c: 1a000004    bne 84 <not_angel+0x2c>
     * 70: e3800c01    orr r0, r0, #256    ; 0x100
     * 74: e28fe00c    add lr, pc, #12
     * 78: e16ff000    msr SPSR_fsxc, r0
     * 7c: e12ef30e    msr ELR_hyp, lr
     * 80: e160006e    eret
     * 84: e121f000    msr CPSR_c, r0
     * 88: e16ff009    msr SPSR_fsxc, r9
     */

    /*
     * abort bit(PSR_A_BIT)ë¥¼ ì„¸ì›Œì„œ abort modeë¡œ ë„˜ì–´ê°€ëŠ” ê²ƒì„ ë§‰ìŒ
     * ì´í›„ operationsì—ì„œ ì•„ë§ˆ data abort exceptionì´ ë°œìƒí•  ìˆ˜ë„ ìˆê¸° ë•Œë¬¸ì¸ ë“¯
     * lrì—ëŠ” 2: labelì˜ ì£¼ì†Œë¥¼ PC ìƒëŒ€ ì£¼ì†Œë¥¼ ì´ìš©í•´ ì €ì¥
     * __MSR_ELR_HYPë¥¼ ìˆ˜í–‰í•˜ê³ ë‚˜ì„œ ëŒì•„ì™”ì„ë•Œ 1: labelì„ ê±´ë„ˆë›°ê³  2: labelë¡œ ê°€ê¸° ìœ„í•´ í•˜ëŠ” ê²ƒìœ¼ë¡œ ìƒê° ë¨
     * BSYMì€ THUMB2_KERNEL ì¸ì§€ì— ë”°ë¼ ì£¼ì†Œ ì§€ì • ë°©ì‹ì´ ë‹¬ë¼ì„œ 2f + 1í•´ì£¼ëŠëƒ ì•„ë‹ˆëƒì˜ ì°¨ì´
     * spsrì˜ c(control), x(extension), s(status), f(flag)ì— reg ê°’ì„ ì €ì¥
     */
	orr	\reg, \reg, #PSR_A_BIT
	adr	lr, BSYM(2f)
	msr	spsr_cxsf, \reg

    /*
     * 2015/07/11 ìŠ¤í„°ë”” ì¢…ë£Œ
     * TODO: __MSR_ELR_HYP(14),__ERET ê°ì ì¡°ì‚¬
     */

    /*
     * __MSR_ELR_HYP(0xE12EF300)
     * __ERET(0xE160006E)
     *
     * ELR_hyp : hyp mode does not provide its own banked copy of lr. Instead, on taking
     *           an exception to hyp mode, the preferred return address is stored in
     *           ELR_hyp, a 32-bit special register implemented for this purpose.
     *           ELR_hyp can be accessed explicitly only by executing mrs(banked register),
     *           msr(banked register).
     *           The ERET instruction uses the value in ELR_hyp as the return address for
     *           the exception.
     *
     * ERET : When executed in hyp mode, exception return loads the pc
     *        from ELR_hyp and loads the cpsr from spsr_hyp
     */

    /*
     * __MSR_ELR_HYP(14)ëŠ” msr (banked register) instructionìœ¼ë¡œ ì¸ì½”ë”© ë¨
     * 14ëŠ” r14(link register)ë¥¼ ë‚˜íƒ€ë‚´ê³  ì´ë¥¼ HYP MODEì—ë§Œ ìˆëŠ” ELR_hypì— ì €ì¥
     * __ERETëŠ” exception return instructionìœ¼ë¡œ ì¸ì½”ë”© ë˜ê³ , HYP_MODEì—ì„œ ì‹¤í–‰ë  ë•Œ
     * pc ê°’ì„ ELR_hypë¡œ ì„¤ì •í•˜ê³ , spsr_hyp ê°’ì„ cpsrì— ì„¤ì •í•¨
     *
     * ì¦‰, ìœ„ì—ì„œ lrì— 2: label ì£¼ì†Œë¥¼ ì €ì¥í•˜ê³ , spsrì— SVC_MODEë¡œ ë¯¸ë¦¬ ì¤€ë¹„í•´ë‘” ìƒíƒœì—ì„œ
     * __MSR_ELR_HYPë¥¼ í†µí•´ ELR_hypì— 2: labelì£¼ì†Œë¥¼ ì €ì¥í•˜ê³ ,
     * __ERETë¥¼ í†µí•´ pcê°’ì„ 2: labelì£¼ì†Œë¡œ ì„¤ì •í›„, cpsrì— spsrê°’ì„ ì„¤ì •í•¨ìœ¼ë¡œì¨
     * HYP_MODEì—ì„œ SVC_MODEë¡œ ì „í™˜ í•¨
     */
	__MSR_ELR_HYP(14)
	__ERET

    /*
     * HYP_MODEê°€ ì•„ë‹Œ ê²½ìš° 1: labelë¡œ jumpí•´ì„œ SVC_MODEë¡œ bit ì„¤ì •í•´ë‘”
     * regë¥¼ cpsr_c(control)ì— ì €ì¥
     * ì¦‰, í˜„ì¬ modeë¥¼ SVC_MODEë¡œ ë³€ê²½
     */
1:	msr	cpsr_c, \reg
2:
#else
/*
 * workaround for possibly broken pre-v6 hardware
 * (akita, Sharp Zaurus C-1000, PXA270-based)
 */
	setmode	PSR_F_BIT | PSR_I_BIT | SVC_MODE, \reg
#endif
.endm

/*
 * STRT/LDRT access macros with ARM and Thumb-2 variants
 */
#ifdef CONFIG_THUMB2_KERNEL

	.macro	usraccoff, instr, reg, ptr, inc, off, cond, abort, t=TUSER()
9999:
	.if	\inc == 1
	\instr\cond\()b\()\t\().w \reg, [\ptr, #\off]
	.elseif	\inc == 4
	\instr\cond\()\t\().w \reg, [\ptr, #\off]
	.else
	.error	"Unsupported inc macro argument"
	.endif

	.pushsection __ex_table,"a"
	.align	3
	.long	9999b, \abort
	.popsection
	.endm

	.macro	usracc, instr, reg, ptr, inc, cond, rept, abort
	@ explicit IT instruction needed because of the label
	@ introduced by the USER macro
	.ifnc	\cond,al
	.if	\rept == 1
	itt	\cond
	.elseif	\rept == 2
	ittt	\cond
	.else
	.error	"Unsupported rept macro argument"
	.endif
	.endif

	@ Slightly optimised to avoid incrementing the pointer twice
	usraccoff \instr, \reg, \ptr, \inc, 0, \cond, \abort
	.if	\rept == 2
	usraccoff \instr, \reg, \ptr, \inc, \inc, \cond, \abort
	.endif

	add\cond \ptr, #\rept * \inc
	.endm

#else	/* !CONFIG_THUMB2_KERNEL */

	.macro	usracc, instr, reg, ptr, inc, cond, rept, abort, t=TUSER()
	.rept	\rept
9999:
	.if	\inc == 1
	\instr\cond\()b\()\t \reg, [\ptr], #\inc
	.elseif	\inc == 4
	\instr\cond\()\t \reg, [\ptr], #\inc
	.else
	.error	"Unsupported inc macro argument"
	.endif

	.pushsection __ex_table,"a"
	.align	3
	.long	9999b, \abort
	.popsection
	.endr
	.endm

#endif	/* CONFIG_THUMB2_KERNEL */

	.macro	strusr, reg, ptr, inc, cond=al, rept=1, abort=9001f
	usracc	str, \reg, \ptr, \inc, \cond, \rept, \abort
	.endm

	.macro	ldrusr, reg, ptr, inc, cond=al, rept=1, abort=9001f
	usracc	ldr, \reg, \ptr, \inc, \cond, \rept, \abort
	.endm

/* Utility macro for declaring string literals */
	.macro	string name:req, string
	.type \name , #object
\name:
	.asciz "\string"
	.size \name , . - \name
	.endm

	.macro check_uaccess, addr:req, size:req, limit:req, tmp:req, bad:req
#ifndef CONFIG_CPU_USE_DOMAINS
	adds	\tmp, \addr, #\size - 1
	sbcccs	\tmp, \tmp, \limit
	bcs	\bad
#endif
	.endm

	.irp	c,,eq,ne,cs,cc,mi,pl,vs,vc,hi,ls,ge,lt,gt,le,hs,lo
	.macro	ret\c, reg
#if __LINUX_ARM_ARCH__ < 6
	mov\c	pc, \reg
#else
	.ifeqs	"\reg", "lr"
	bx\c	\reg
	.else
	mov\c	pc, \reg
	.endif
#endif
	.endm
	.endr

	.macro	ret.w, reg
	ret	\reg
#ifdef CONFIG_THUMB2_KERNEL
	nop
#endif
	.endm

#endif /* __ASM_ASSEMBLER_H__ */
